{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Run this!\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "from keras.callbacks import LambdaCallback, ModelCheckpoint\n",
    "import numpy as np\n",
    "import random, sys, io, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "﻿The Time Traveller (for so it will be convenient to speak of him) was expounding a recondite matter to us. His pale grey eyes shone and twinkled, and his usually pale face was flushed and animated.\ntext length: 174201 characters\nunique characters: 39\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# REPLACE THE <addFileName> BELOW WITH The Time Machine\n",
    "###\n",
    "text = io.open('Data/The Time Machine.txt', encoding = 'UTF-8').read()\n",
    "###\n",
    "# Let's have a look at some of the text\n",
    "print(text[0:198])\n",
    "\n",
    "# This cuts out punctuation and make all the characters lower case\n",
    "text = text.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "# Character index dictionary\n",
    "charset = sorted(list(set(text)))\n",
    "index_from_char = dict((c, i) for i, c in enumerate(charset))\n",
    "char_from_index = dict((i, c) for i, c in enumerate(charset))\n",
    "\n",
    "print('text length: %s characters' %len(text))\n",
    "print('unique characters: %s' %len(charset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of training sequences: 43541\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# REPLACE <sequenceLength> WITH 40 AND <step> WITH 4\n",
    "###\n",
    "sequence_length = 40\n",
    "step = 4\n",
    "###\n",
    "sequences = []\n",
    "target_chars = []\n",
    "for i in range(0, len(text) - sequence_length, step):\n",
    "    sequences.append([text[i: i + sequence_length]])\n",
    "    target_chars.append(text[i + sequence_length])\n",
    "print('number of training sequences:', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot vectorise\n",
    "X = np.zeros((len(sequences), sequence_length, len(charset)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(charset)), dtype=np.bool)\n",
    "###\n",
    "# REPLACE THE <addSequences> BELOW WITH sequences\n",
    "###\n",
    "for n, sequence in enumerate(sequences):\n",
    "###\n",
    "    for m, character in enumerate(list(sequence[0])):\n",
    "        X[n, m, index_from_char[character]] = 1\n",
    "    y[n, index_from_char[target_chars[n]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "###\n",
    "# REPLACE THE <addLSTM> BELOW WITH LSTM (use uppercase) AND <addLayerSize> WITH 128\n",
    "###\n",
    "model.add(LSTM(128, input_shape = (X.shape[1], X.shape[2])))\n",
    "###\n",
    "###\n",
    "# REPLACE THE <addSoftmaxFunction> with 'softmax' (INCLUDING THE QUOTES)\n",
    "###\n",
    "model.add(Dense(y.shape[1], activation = 'softmax'))\n",
    "###\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this, but do not edit.\n",
    "# It helps generate the text and save the model epochs.\n",
    "# Generate new text\n",
    "def on_epoch_end(epoch, _):\n",
    "    diversity = 0.5\n",
    "    print('\\n### Generating text with diversity %0.2f' %(diversity))\n",
    "\n",
    "    start = random.randint(0, len(text) - sequence_length - 1)\n",
    "    seed = text[start: start + sequence_length]\n",
    "    print('### Generating with seed: \"%s\"' %seed[:40])\n",
    "\n",
    "    output = seed[:40].lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    print(output, end = '')\n",
    "\n",
    "    for i in range(500):\n",
    "        x_pred = np.zeros((1, sequence_length, len(charset)))\n",
    "        for t, char in enumerate(output):\n",
    "            x_pred[0, t, index_from_char[char]] = 1.\n",
    "\n",
    "        predictions = model.predict(x_pred, verbose=0)[0]\n",
    "        exp_preds = np.exp(np.log(np.asarray(predictions).astype('float64')) / diversity)\n",
    "        next_index = np.argmax(np.random.multinomial(1, exp_preds / np.sum(exp_preds), 1))\n",
    "        next_char = char_from_index[next_index]\n",
    "\n",
    "        output = output[1:] + next_char\n",
    "\n",
    "        print(next_char, end = '')\n",
    "    print()\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "# Save the model\n",
    "checkpoint = ModelCheckpoint('Models/model-epoch-{epoch:02d}.hdf5', \n",
    "                             monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "341/341 [==============================] - ETA: 0s - loss: 2.7463\n",
      "### Generating text with diversity 0.50\n",
      "### Generating with seed: \"eed”  “agreed” said the editor and the r\"\n",
      "eed”  “agreed” said the editor and the rst here toy ss an csec tele toos thert ore cane there nrepestoo ene ons then thef in saaand sser nena sand tae toe the thaw noswaed tous te thee thed itin ther toaan toe sos ole ani shod ther shee ace feoe dod cahd tiomde the stiled sone tnon tyo gennt ane sthet ine  henose taseosleas tant oiu toe the thes one s toed ten ant rog osgetee the an spon sonetafthe the soas the bain isl the tire thele the ine thenol thesin thbee on the the sont tfen tee terss oathe  aand the d osandand aas the ies the\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.74630, saving model to Models\\model-epoch-01.hdf5\n",
      "341/341 [==============================] - 127s 373ms/step - loss: 2.7463\n",
      "Epoch 2/3\n",
      "341/341 [==============================] - ETA: 0s - loss: 2.3581\n",
      "### Generating text with diversity 0.50\n",
      "### Generating with seed: \"ght or ten of these exquisite creatures \"\n",
      "ght or ten of these exquisite creatures here the s aad the nerely in the band of the the the the the the mat wi t ind thi and theni ind an  aod thin sod an in and me orer in the the re was sor the s in inl the the f ire thi colos ther wind in the kinl has an thin ind the the dinc are and the the ule and in th the sist and ar sans wa hed sere ind she the the thind aud an bat the  for and on and weve mas the ferit corle s and to sond ind and and a fis ald the s and an af and in the rare sith tho the to the the the wad sas thin lo werore\n",
      "\n",
      "Epoch 00002: loss improved from 2.74630 to 2.35807, saving model to Models\\model-epoch-02.hdf5\n",
      "341/341 [==============================] - 152s 446ms/step - loss: 2.3581\n",
      "Epoch 3/3\n",
      "341/341 [==============================] - ETA: 0s - loss: 2.2180\n",
      "### Generating text with diversity 0.50\n",
      "### Generating with seed: \"form to remark these apertures for when \"\n",
      "form to remark these apertures for when ing and and thang foresting or an the pough and the thor the thaca on the sof the hint of and the and on the berle wand me the want in of meme the shant and werigl tho the the s and the hi toon there the fit had the las as and ion fe wale the bone the soun the weis pont the sat in the tiant of the the thonn har the thint as borte and the the fime and and and she the in the the cact an the in the of ues if of and and in the then or moce and and oudead and in and the ind the spok hed the tor the s\n",
      "\n",
      "Epoch 00003: loss improved from 2.35807 to 2.21801, saving model to Models\\model-epoch-03.hdf5\n",
      "341/341 [==============================] - 147s 430ms/step - loss: 2.2180\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x279fed56df0>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "###\n",
    "# REPLACE <addPrintCallback> WITH print_callback AND <addCheckpoint> WITH checkpoint\n",
    "###\n",
    "model.fit(X, y, batch_size = 128, epochs = 3, callbacks = [print_callback, checkpoint])\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading model... model loaded\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "print(\"loading model... \", end = '')\n",
    "\n",
    "###\n",
    "# REPLACE <addLoadModel> BELOW WITH load_model\n",
    "###\n",
    "model = load_model('Models/arthur-model-epoch-30.hdf5')\n",
    "###\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam')\n",
    "###\n",
    "\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "text length: 3645951 characters\nunique characters: 43\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# REPLACE <addFilePath> BELOW WITH 'Data/Arthur tales.txt' (INCLUDING THE QUOTATION MARKS)\n",
    "###\n",
    "text = io.open('Data/Arthur tales.txt', encoding='UTF-8').read()\n",
    "###\n",
    "\n",
    "# Cut out punctuation and make lower case\n",
    "text = text.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "# Character index dictionary\n",
    "charset = sorted(list(set(text)))\n",
    "index_from_char = dict((c, i) for i, c in enumerate(charset))\n",
    "char_from_index = dict((i, c) for i, c in enumerate(charset))\n",
    "\n",
    "print('text length: %s characters' %len(text))\n",
    "print('unique characters: %s' %len(charset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "### Generating text with diversity 0.50\n",
      "### Generating with seed: \"a sentence of at least 50 characters\"\n",
      "a sentence of at least 50 charactersrswawwwgwwwwwwwrrwt  rwwwrw    ww  wwwwawdw    ww v w w  wwdvw      wwlwn dw   waa  aw   www  w ww wwvvwwwrs ntwrrv rwawww    wwd  wvww   wwwdw  wwd   vwwww    wdlww   dw wrwwrw  w wwdw    wdr    wwaww  ww  lwwwwwwe a     wamw w   www  www  wwwww ww w wwwww     w wwd  d www  ww w  ww ww  ww w r wrw w     wwwdl www ww  wwaow    wwrdwwwwuwaww uwww ww    www wwgw  wwwwr wwrw w w      wwwwwdw  ww aw  aw    ww   wdr    wwoewdw www  wwaww    w  wwwwwdw   udwwwynwa w     wwarr w r w  www w wwww    www www w w aw    w r    ww wwwrw d wwww     w wwwwwww  wwwnaew wwww      w wwnwdw wd  w wwwwwwwsrrw     warw  ww   wwwwnwd  wwwwwn wwd  w wwwwwwwwirw wn     rwwaww      ywwwwdw    ww wwwwwwww w w    wwrdwdw    w  a  rr     ww awwdn r r   ww  wwwaww  wwww r w wdrvw    ww a   wwwd  wwwdw   ww      ww wawww  wwr wwd    wwwww ww ww wwr   wiww    ww wwww wwwn  www   www  wr wwwadwwlw wdt   wwwdwrrww w     wr  wwww   ww ww w ww  nw     wnwww wwwaawwwa  a    waww    ww wwgw  nr ww ww  wwwodw wwennww wwwnw\n"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "diversity = 0.5\n",
    "print('\\n### Generating text with diversity %0.2f' %(diversity))\n",
    "###\n",
    "# REPLACE <sequenceLength> BELOW WITH 50\n",
    "###\n",
    "sequence_length = 50\n",
    "###\n",
    "# Next we'll make a starting point for our text generator\n",
    "###\n",
    "# REPLACE <writeSentence> WITH A SENTENCE OF AT LEAST 50 CHARACTERS\n",
    "###\n",
    "seed = \"A SENTENCE OF AT LEAST 50 CHARACTERS\"\n",
    "###\n",
    "seed = seed.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "###\n",
    "# OR, ALTERNATIVELY, UNCOMMENT THE FOLLOWING TWO LINES AND GRAB A RANDOM STRING FROM THE TEXT FILE\n",
    "###\n",
    "#start = random.randint(0, len(text) - sequence_length - 1)\n",
    "#seed = text[start: start + sequence_length]\n",
    "###\n",
    "print('### Generating with seed: \"%s\"' %seed[:40])\n",
    "\n",
    "output = seed[:sequence_length].lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "print(output, end = '')\n",
    "###\n",
    "# REPLACE THE <numCharsToGenerate> BELOW WITH THE NUMBER OF CHARACTERS WE WISH TO GENERATE, e.g. 1500\n",
    "###\n",
    "for i in range(1000):\n",
    "###\n",
    "    x_pred = np.zeros((1, sequence_length, len(charset)))\n",
    "    for t, char in enumerate(output):\n",
    "        x_pred[0, t, index_from_char[char]] = 1.\n",
    "\n",
    "    predictions = model.predict(x_pred, verbose=0)[0]\n",
    "    exp_preds = np.exp(np.log(np.asarray(predictions).astype('float64')) / diversity)\n",
    "    next_index = np.argmax(np.random.multinomial(1, exp_preds / np.sum(exp_preds), 1))\n",
    "    next_char = char_from_index[next_index]\n",
    "\n",
    "    output = output[1:] + next_char\n",
    "\n",
    "    print(next_char, end = '')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}